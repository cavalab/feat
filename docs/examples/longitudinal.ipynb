{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Longitudinal Data\n",
    "=======================\n",
    "\n",
    "This example demonstrates how to do cross validation with longitudinal\n",
    "data.\n",
    "By *longitudinal*, we mean predictors for specific samples that have more than one value. \n",
    "This could be time series data or any other sequential data we might want to model. \n",
    "\n",
    "\n",
    "Example Patient Data\n",
    "------------------------------\n",
    "\n",
    "First, we generate some example data and store it using this script: https://github.com/lacava/feat/blob/master/docs/examples/longitudinal/generate_example_longitudinal_data.py. \n",
    "\n",
    "Let’s imagine we have patient data from a hospital. \n",
    "This means we have measurements from different visits, with different numbers of measurements from different\n",
    "patients collected in non-uniform intervals.\n",
    "In this example, we make up a risk model in which risk increases for a\n",
    "patient with an increasing body mass index (BMI) and a high maximum\n",
    "glucose level in their blood panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "random_state=42\n",
    "\n",
    "df = pd.read_csv('data/d_example_patients.csv')\n",
    "df.drop('id',axis=1,inplace=True)\n",
    "X = df.drop('target',axis=1)\n",
    "y = df['target']\n",
    "zfile = 'data/d_example_patients_long.csv'\n",
    "kf = KFold(n_splits=3,shuffle=True,random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Next we set up the learner. We need to declare the longitudinal\n",
    "operators we want to search over. They are defined as a comma-delimited\n",
    "list of strings using the ``functions`` argument. In this case, the\n",
    "operators on the second row of the declaration below all operate on\n",
    "longitudinal data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feat import Feat\n",
    "\n",
    "clf = Feat(max_depth=5,\n",
    "           max_dim=5,\n",
    "           gens = 100,\n",
    "           pop_size = 100,\n",
    "           max_time = 30, # seconds\n",
    "           verbosity=2,\n",
    "           shuffle=True,\n",
    "           normalize=False, # don't normalize input data\n",
    "           functions=\"and,or,not,split,split_c,\"\n",
    "                     \"mean,median,max,min,variance,skew,kurtosis,slope,count\",\n",
    "           backprop=True,\n",
    "           batch_size=10,\n",
    "           iters=10,\n",
    "           random_state=random_state,\n",
    "           n_jobs=1,\n",
    "           simplify=0.01    # prune final representations\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation\n",
    "----------------\n",
    "\n",
    "Cross validation works a little bit differently with longitudinal data. \n",
    "The block below shows how to train a model using Kfold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "\n",
    "for train_idx, test_idx in kf.split(X,y):\n",
    "    # print('train_idx:',train_idx)\n",
    "    # note that the train index is passed to FEAT's fit method\n",
    "    clf.fit(X.loc[train_idx],y.loc[train_idx],zfile,train_idx) \n",
    "    scores.append(clf.score(X.loc[test_idx],y.loc[test_idx],zfile,test_idx))\n",
    "\n",
    "print('scores:',scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Interpretation\n",
    "--------------------\n",
    "\n",
    "Now let’s fit a model to all the data and try to interpret it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit to all data\n",
    "\n",
    "print('fitting longer to all data...')\n",
    "clf.verbosity = 2\n",
    "clf.fit(X,y,zfile,np.arange(len(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To see the learned representation, we run ``clf.get_representation()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_representation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our final representation is composed of ``slope(z_bmi)`` and\n",
    "``max(z_glucose)``, both of which we know to be correct features for\n",
    "this simulated dataset. The best training representation displays clear\n",
    "overfitting, highlighting the importance of using archive validation for\n",
    "model selection.\n",
    "We can also look at the representation with the model weights, sorted by\n",
    "magnitude, using ``clf.get_model()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.get_model())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View runtime stats\n",
    "------------------\n",
    "\n",
    "FEAT stores statistics about the training procedure in a dictionary `clf.stats_`. \n",
    "An example of plotting from this dictionary is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.stats_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(clf.stats_['time'], clf.stats_['min_loss'], 'b', label='training loss')\n",
    "plt.plot(clf.stats_['time'], clf.stats_['min_loss_v'], 'r', label='validation loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('MSE')\n",
    "plt.gca().set_yscale('log')\n",
    "plt.gca().set_xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(clf.stats_['time'], clf.stats_['med_complexity'], 'b', label='median complexity')\n",
    "# plt.plot(clf.stats_['time'], clf.stats_['med_size'], 'r', label='median size')\n",
    "plt.legend()\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Median Complexity')\n",
    "# plt.gca().set_yscale('log')\n",
    "plt.gca().set_xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing the representation\n",
    "------------------------------\n",
    "\n",
    "Here we take the two relevant features and plot the data with them.\n",
    "This shows us the risk surface as a function of these learned features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the representation\n",
    "\n",
    "proj = clf.transform(X,zfile,np.arange(len(X)))\n",
    "\n",
    "print('proj:',proj.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.patheffects as PathEffects\n",
    "from matplotlib import cm\n",
    "\n",
    "cm = plt.cm.get_cmap('RdBu')\n",
    "# We choose a color palette with seaborn.\n",
    "# palette = np.array(sns.color_palette(\"cividis\", np.unique(y)))\n",
    "\n",
    "# We create a scatter plot.\n",
    "f = plt.figure(figsize=(6, 6))\n",
    "ax = plt.subplot(aspect='equal')\n",
    "sc = ax.scatter(proj[:,0], proj[:,1], lw=0, s=20,\n",
    "                c=y, cmap=cm)\n",
    "plt.colorbar(sc)\n",
    "# sc.colorbar()\n",
    "ax.axis('square')\n",
    "# ax.axis('off')\n",
    "ax.axis('tight')\n",
    "\n",
    "# add labels from representation\n",
    "rep = [r.split('[')[-1] for r in clf.get_representation().split(']') if r != '']\n",
    "print('rep:',rep)\n",
    "plt.xlabel(rep[0])\n",
    "plt.ylabel(rep[1])\n",
    "\n",
    "# plt.savefig('longitudinal_representation.svg', dpi=120)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
